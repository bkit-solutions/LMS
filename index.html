<!DOCTYPE html>
<html>

<head>
    <title>Proctoring System</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <!-- TensorFlow.js and COCO-SSD for Object Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f2f5;
            display: flex;
            height: 100vh;
        }

        /* Main Exam Area (Placeholder) */
        .exam-container {
            flex: 1;
            padding: 40px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .exam-paper {
            background: white;
            width: 80%;
            height: 80%;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            padding: 40px;
            text-align: center;
        }

        /* Stats Panel */
        .sidebar {
            width: 300px;
            background: white;
            border-left: 1px solid #ddd;
            padding: 20px;
            display: flex;
            flex-direction: column;
        }

        .stat-card {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
            border-left: 4px solid #007bff;
        }

        .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #333;
        }

        .stat-label {
            font-size: 14px;
            color: #666;
        }

        /* Webcam Widget */
        .camera-widget {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 280px;
            height: 210px;
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
            border: 4px solid transparent;
            transition: border-color 0.3s;
        }

        .camera-widget.violation {
            border-color: #dc3545;
        }

        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
            /* Mirror effect */
        }

        /* Hide debug canvas but keep it in DOM for processing */
        canvas {
            display: none;
        }

        #status {
            margin-top: 10px;
            font-size: 14px;
            color: #666;
        }

        .alert-badge {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(220, 53, 69, 0.9);
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: bold;
            display: none;
        }
    </style>
</head>

<body>
    <!-- Main Content -->
    <div class="exam-container">
        <div class="exam-paper">
            <h1>Online Exam</h1>
            <p>Please focus on the screen. Your session is being proctored.</p>
            <div id="status">Initializing system...</div>
            <button id="startBtn" onclick="startWebcam()"
                style="margin-top: 20px; padding: 10px 20px; cursor: pointer;">Start Exam & Proctoring</button>
        </div>
    </div>

    <!-- Sidebar Stats -->
    <div class="sidebar">
        <h2>Session Report</h2>
        <div class="stat-card" style="border-color: #dc3545;">
            <div class="stat-value" id="count-HEAD_TURNED">0</div>
            <div class="stat-label">Head Turns</div>
        </div>
        <div class="stat-card" style="border-color: #ffc107;">
            <div class="stat-value" id="count-HEAD_TILT">0</div>
            <div class="stat-label">Head Tilts</div>
        </div>
        <div class="stat-card" style="border-color: #17a2b8;">
            <div class="stat-value" id="count-GAZE_AWAY">0</div>
            <div class="stat-label">Look Aways</div>
        </div>
        <div class="stat-card" style="border-color: #6c757d;">
            <div class="stat-value" id="count-MULTIPLE_PEOPLE">0</div>
            <div class="stat-label">Multiple People</div>
        </div>
        <div class="stat-card" style="border-color: #d63384;">
            <div class="stat-value" id="count-FACE_VISIBILITY">0</div>
            <div class="stat-label">Face Visibility Issues</div>
        </div>
        <div class="stat-card" style="border-color: #20c997;">
            <div class="stat-value" id="count-MOBILE_DETECTED">0</div>
            <div class="stat-label">Mobile Detected</div>
        </div>
        <div class="stat-card" style="border-color: #fd7e14;">
            <div class="stat-value" id="count-AUDIO_DETECTED">0</div>
            <div class="stat-label">Audio Incidents (Speech)</div>
        </div>
    </div>

    <!-- Floating Camera Widget -->
    <div class="camera-widget" id="cameraContainer">
        <div class="alert-badge" id="alertBadge">VIOLATION DETECTED</div>
        <video id="video" playsinline muted></video> <!-- Muted to prevent feedback loop -->
        <canvas id="canvas"></canvas> <!-- Hidden canvas for processing -->
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const status = document.getElementById('status');
        const cameraContainer = document.getElementById('cameraContainer');
        const alertBadge = document.getElementById('alertBadge');

        let faceMesh = null;
        let objectDetector = null; // COCO-SSD Model
        let camera = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;

        // Advanced Audio Tracking State
        let speechStartTime = 0;
        let speechBurstHistory = [];

        // Object Detection State
        let lastObjectCheck = 0;
        let isMobileDetected = false;

        // State tracking for debounce
        const violationCounts = {
            HEAD_TURNED: 0,
            HEAD_TILT: 0,
            GAZE_AWAY: 0,
            MULTIPLE_PEOPLE: 0,
            FACE_VISIBILITY: 0,
            MOBILE_DETECTED: 0,
            AUDIO_DETECTED: 0
        };

        const violationState = {
            HEAD_TURNED: { active: false },
            HEAD_TILT: { active: false },
            GAZE_AWAY: { active: false },
            MULTIPLE_PEOPLE: { active: false },
            FACE_VISIBILITY: { active: false },
            MOBILE_DETECTED: { active: false },
            AUDIO_DETECTED: { active: false }
        };

        async function initML() {
            status.textContent = 'Loading AI Models (Face + Objects)...';

            // Load COCO-SSD
            objectDetector = await cocoSsd.load();

            // Load FaceMesh
            const faceMeshConfig = {
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
            };

            faceMesh = new FaceMesh({
                locateFile: faceMeshConfig.locateFile,
            });

            faceMesh.setOptions({
                maxNumFaces: 4,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onResults);
            status.textContent = 'System Ready. Please start the exam.';
        }

        function analyzeFace(landmarks) {
            if (!landmarks || landmarks.length === 0) return ['NO_FACE'];

            const face = landmarks;
            const currentFrameViolations = [];

            // Landmarks
            const nose = face[1];
            const leftEyeOuter = face[33];
            const leftEyeInner = face[133];
            const rightEyeInner = face[362];
            const rightEyeOuter = face[263];

            // 1. HEAD ORIENTATION
            const dx = rightEyeOuter.x - leftEyeOuter.x;
            const dy = rightEyeOuter.y - leftEyeOuter.y;
            const rollAngle = Math.atan2(dy, dx) * 180 / Math.PI;

            if (Math.abs(rollAngle) > 20) currentFrameViolations.push('HEAD_TILT');

            const eyesMidX = (leftEyeOuter.x + rightEyeOuter.x) / 2;
            const eyeDistance = Math.sqrt(dx * dx + dy * dy);
            const noseOffsetX = (nose.x - eyesMidX) / eyeDistance;

            if (Math.abs(noseOffsetX) > 0.35) currentFrameViolations.push('HEAD_TURNED');

            // 2. GAZE
            if (face[468] && face[473]) {
                const leftIris = face[468];
                const rightIris = face[473];

                const leftEyeWidth = Math.abs(leftEyeInner.x - leftEyeOuter.x);
                const leftEyeMid = (leftEyeInner.x + leftEyeOuter.x) / 2;
                const leftGazeOffset = (leftIris.x - leftEyeMid) / leftEyeWidth;

                const rightEyeWidth = Math.abs(rightEyeOuter.x - rightEyeInner.x);
                const rightEyeMid = (rightEyeInner.x + rightEyeOuter.x) / 2;
                const rightGazeOffset = (rightIris.x - rightEyeMid) / rightEyeWidth;

                if (Math.abs(leftGazeOffset) > 0.6 || Math.abs(rightGazeOffset) > 0.6) {
                    currentFrameViolations.push('GAZE_AWAY');
                }
            }

            // 3. VISIBILITY/SIZE
            const faceBounds = getFaceBounds(face);
            const faceSize = faceBounds.width;

            if (faceSize < 0.1 || faceSize > 0.8) currentFrameViolations.push('FACE_VISIBILITY');

            return currentFrameViolations;
        }

        function getFaceBounds(landmarks) {
            let minX = 1, minY = 1, maxX = 0, maxY = 0;
            for (let landmark of landmarks) {
                minX = Math.min(minX, landmark.x);
                minY = Math.min(minY, landmark.y);
                maxX = Math.max(maxX, landmark.x);
                maxY = Math.max(maxY, landmark.y);
            }
            return { width: maxX - minX, height: maxY - minY };
        }

        function onResults(results) {
            const currentViolations = new Set();

            // 1. Video Analysis
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                if (results.multiFaceLandmarks.length > 1) {
                    currentViolations.add('MULTIPLE_PEOPLE');
                }

                for (const landmarks of results.multiFaceLandmarks) {
                    const violations = analyzeFace(landmarks);
                    violations.forEach(v => currentViolations.add(v));
                }
            }

            // 2. Object Detection (Mobile) - Passed from Camera Loop
            if (isMobileDetected) {
                currentViolations.add('MOBILE_DETECTED');
            }

            // 3. Audio Analysis
            const isSpeech = detectSpeech();
            const now = Date.now();

            if (isSpeech) {
                if (speechStartTime === 0) speechStartTime = now;

                // Rule: Continuous Speech > 2 seconds
                if (now - speechStartTime > 2000) {
                    currentViolations.add('AUDIO_DETECTED');
                }
            } else {
                if (speechStartTime > 0) {
                    const duration = now - speechStartTime;
                    if (duration > 500) {
                        speechBurstHistory.push(now);
                    }
                    speechStartTime = 0;
                }
            }

            // Rule: 3+ Bursts in 10 seconds
            speechBurstHistory = speechBurstHistory.filter(t => now - t < 10000);
            if (speechBurstHistory.length >= 3) {
                currentViolations.add('AUDIO_DETECTED');
            }

            updateViolationStats(currentViolations);
        }

        function detectSpeech() {
            if (!analyser) return false;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteFrequencyData(dataArray);

            const binSize = audioContext.sampleRate / analyser.fftSize;
            const startBin = Math.floor(300 / binSize);
            const endBin = Math.floor(3400 / binSize);

            let voiceEnergy = 0;
            for (let i = startBin; i <= endBin; i++) {
                voiceEnergy += dataArray[i];
            }
            const averageVoiceEnergy = voiceEnergy / (endBin - startBin + 1);

            return averageVoiceEnergy > 45;
        }

        function updateViolationStats(activeViolations) {
            let isAnyViolation = false;
            let alertText = '';

            for (const type in violationState) {
                if (activeViolations.has(type)) {
                    isAnyViolation = true;
                    // Labels
                    if (type === 'AUDIO_DETECTED') alertText = 'SPEECH DETECTED';
                    else if (type === 'MOBILE_DETECTED') alertText = 'PHONE DETECTED';
                    else alertText = type.replace('_', ' ');

                    if (!violationState[type].active) {
                        violationState[type].active = true;
                        violationCounts[type]++;
                        updateDisplay(type);
                    }
                } else {
                    violationState[type].active = false;
                }
            }

            if (isAnyViolation) {
                cameraContainer.classList.add('violation');
                alertBadge.textContent = alertText;
                alertBadge.style.display = 'block';
            } else {
                cameraContainer.classList.remove('violation');
                alertBadge.style.display = 'none';
            }
        }

        function updateDisplay(type) {
            const el = document.getElementById(`count-${type}`);
            if (el) el.textContent = violationCounts[type];
        }

        async function startWebcam() {
            document.getElementById('startBtn').style.display = 'none';
            status.textContent = 'Proctoring Active';

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480 },
                    audio: true
                });
                video.srcObject = stream;

                // Audio Setup
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                microphone = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 1024;
                microphone.connect(analyser);

                await new Promise(resolve => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve();
                    };
                });

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                camera = new Camera(video, {
                    onFrame: async () => {
                        // 1. Run Object Detection occasionally (every ~500ms)
                        // COCO-SSD is heavy, don't run every frame
                        const now = Date.now();
                        if (now - lastObjectCheck > 500 && objectDetector) {
                            lastObjectCheck = now;
                            const predictions = await objectDetector.detect(video);
                            // Check for 'cell phone' class
                            isMobileDetected = predictions.some(p => p.class === 'cell phone');
                        }

                        // 2. Run Face Mesh (Every frame)
                        await faceMesh.send({ image: video });
                    },
                    width: 640,
                    height: 480
                });
                camera.start();
            } catch (err) {
                console.error(err);
                status.textContent = 'Error: ' + err.message + '. Please allow camera and mic permissions.';
            }
        }

        initML();
    </script>
</body>

</html>